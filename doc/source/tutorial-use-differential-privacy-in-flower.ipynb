{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Privacy in flwr Part 2\n",
    "## Step by step guide\n",
    "\n",
    "In this tutorial, we will learn the recommended best practices to build an effective differential privacy setting in federated learning using Flower. \n",
    "\n",
    "The documentation will provide a step-by-step guide, code examples, and best practices for implementing user-level differential privacy gurantees in federated learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may consider to look at the previous tutorial where we introduced Differential Privacy in federated learning with Flower ([part 1](Flower-5-Differential-Privacy-in-flwr-part-1.ipynb)), the introductory notebook (again, using [Flower](https://flower.dev/) and [PyTorch](https://pytorch.org/))..\n",
    "\n",
    "\n",
    "> [Star Flower on GitHub](https://github.com/adap/flower) ⭐️ and join the Flower community on Slack to connect, ask questions, and get help: [Join Slack](https://flower.dev/join-slack) 🌼 We'd love to hear from you in the `#introductions` channel! And if anything is unclear, head over to the `#questions` channel.\n",
    "\n",
    "\n",
    "In this notebook, we will demonstrate the recommended best practice for training models with user-level Differential Privacy using.\n",
    " \n",
    "We will train (30 rounds) a model with high trade-off between utility and privacy on the CIFAR-10 training and test set, partition them into ten smaller datasets. If we used more training rounds, we could certainly have a higher-accuracy private model, but not as high as a model trained without DP.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependencies\n",
    "\n",
    "Next, we install the necessary packages for PyTorch (`torch` and `torchvision`) and Flower (`flwr`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/Elnathan%20Tiokou/flower\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: flwr[simulation] in c:\\users\\elnathan tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: torch in c:\\users\\elnathan tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\elnathan tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\elnathan tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages (3.7.2)\n",
      "INFO: pip is looking at multiple versions of flwr[simulation] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting flwr[simulation]\n",
      "  Using cached flwr-1.4.0-py3-none-any.whl (157 kB)\n",
      "  Using cached flwr-1.3.0-py3-none-any.whl (139 kB)\n",
      "  Using cached flwr-1.2.0-py3-none-any.whl (133 kB)\n",
      "  Using cached flwr-1.1.0-py3-none-any.whl (121 kB)\n",
      "  Using cached flwr-1.0.0-py3-none-any.whl (90 kB)\n",
      "  Using cached flwr-0.19.0-py3-none-any.whl (106 kB)\n",
      "  Using cached flwr-0.18.0-py3-none-any.whl (106 kB)\n",
      "INFO: pip is still looking at multiple versions of flwr[simulation] to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached flwr-0.17.0-py3-none-any.whl (229 kB)\n",
      "  Using cached flwr-0.16.0-py3-none-any.whl (216 kB)\n",
      "  Using cached flwr-0.15.0-py3-none-any.whl (214 kB)\n",
      "  Using cached flwr-0.14.0-py3-none-any.whl (212 kB)\n",
      "  Using cached flwr-0.13.0-py3-none-any.whl (202 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached flwr-0.12.0-py3-none-any.whl (199 kB)\n",
      "  Using cached flwr-0.11.0-py3-none-any.whl (183 kB)\n",
      "  Using cached flwr-0.10.0-py3-none-any.whl (182 kB)\n",
      "  Using cached flwr-0.9.0-py3-none-any.whl (178 kB)\n",
      "  Using cached flwr-0.7.0-py3-none-any.whl (167 kB)\n",
      "  Using cached flwr-0.6.0-py3-none-any.whl (167 kB)\n",
      "  Using cached flwr-0.5.0-py3-none-any.whl (159 kB)\n",
      "  Using cached flwr-0.4.0-py3-none-any.whl (158 kB)\n",
      "  Using cached flwr-0.3.0-py3-none-any.whl (158 kB)\n",
      "  Using cached flwr-0.2.0-py3-none-any.whl (158 kB)\n",
      "  Using cached flwr-0.1.1-py3-none-any.whl (156 kB)\n",
      "  Using cached flwr-0.1.0-py3-none-any.whl (156 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 1.5.0 depends on flwr 1.5.0 (Installed)\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 1.4.0 depends on flwr 1.4.0 (from https://files.pythonhosted.org/packages/53/ce/8ff487edabfa3dd787e35153b47f34a04389247d1859c44529aa92620310/flwr-1.4.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.7,<4.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 1.3.0 depends on flwr 1.3.0 (from https://files.pythonhosted.org/packages/5f/09/dce794ed093f9aba0848e38345341565197d0ef1f8dc0438e554ff0da1a1/flwr-1.3.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.7,<4.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 1.2.0 depends on flwr 1.2.0 (from https://files.pythonhosted.org/packages/56/e6/d62a5972e0dfc703bb0686f2bf07c60ec3d60b07e48b32290573ad276989/flwr-1.2.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.7,<4.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 1.1.0 depends on flwr 1.1.0 (from https://files.pythonhosted.org/packages/91/8d/8c7bf946985396ab01b74334d9fff30249c03c35953f6ff7514605c84804/flwr-1.1.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.7,<4.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 1.0.0 depends on flwr 1.0.0 (from https://files.pythonhosted.org/packages/f4/85/12e5d0a59c16b85f2f086e2253a806d1ea5534623f1d88516a124592f483/flwr-1.0.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.7,<4.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.19.0 depends on flwr 0.19.0 (from https://files.pythonhosted.org/packages/5f/99/7088765333533d706bf474df2509a4222401c841bc309e65e2cd5e0241e1/flwr-0.19.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.7,<4.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.18.0 depends on flwr 0.18.0 (from https://files.pythonhosted.org/packages/67/c3/62c1d5063acaf68f2421e85ae456047b40f8ddaab7595f7aeeaea9c93564/flwr-0.18.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.2,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.17.0 depends on flwr 0.17.0 (from https://files.pythonhosted.org/packages/ff/42/70923f4f0dedf5be448418b981e7a675d610151659f1eb3b3b30dd2e2719/flwr-0.17.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.2,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.16.0 depends on flwr 0.16.0 (from https://files.pythonhosted.org/packages/8a/8f/1e8c6c045c32c278e6fb792d4b1eb311c83b10bc10ddd879e0b34b796919/flwr-0.16.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.2,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.15.0 depends on flwr 0.15.0 (from https://files.pythonhosted.org/packages/36/7a/4940dd4013934cf62b84357d26a0bc05bed4621a3c323951c12216ded39d/flwr-0.15.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.2,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.14.0 depends on flwr 0.14.0 (from https://files.pythonhosted.org/packages/3d/c9/1d1a83866857d2899103c76db5b4b1034b9c29aea276da09749a158275da/flwr-0.14.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.1,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.13.0 depends on flwr 0.13.0 (from https://files.pythonhosted.org/packages/36/3c/f20d46dcf99d0b38173f833d408ec70d0dcdb2612db040cf7b2d2e35c11c/flwr-0.13.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.1,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.12.0 depends on flwr 0.12.0 (from https://files.pythonhosted.org/packages/78/af/23036a4d9ce91a2074ba86b61ba57c6b07510588db5523103505b5585cbb/flwr-0.12.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.1,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.11.0 depends on flwr 0.11.0 (from https://files.pythonhosted.org/packages/72/b5/45a34d2d2807a21262c577234874eb1610814d5223b00d78bf208fb91646/flwr-0.11.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.1,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.10.0 depends on flwr 0.10.0 (from https://files.pythonhosted.org/packages/26/4b/8d3a96311f5ae070732acbe58b037d5736fdcc3e5686a1c5579d5e6e3e87/flwr-0.10.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.9.0 depends on flwr 0.9.0 (from https://files.pythonhosted.org/packages/e5/43/e4e2b2063c8c428e5208d3c672aaad71239e348ee204e6231806b971816c/flwr-0.9.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.7.0 depends on flwr 0.7.0 (from https://files.pythonhosted.org/packages/72/c2/17f4cd175da75443256a10bcea08e7610869906d3ae92f30124342db4bf9/flwr-0.7.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.6.0 depends on flwr 0.6.0 (from https://files.pythonhosted.org/packages/2a/b7/769e4bb61acb82eb34b7bf6b903f3c90cb09fb62ae3590112a2345846faf/flwr-0.6.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.5.0 depends on flwr 0.5.0 (from https://files.pythonhosted.org/packages/f3/43/b5ec9c52b28443ba6503415d0b8dd60cea17f91cc6725460ac5873fb266e/flwr-0.5.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.4.0 depends on flwr 0.4.0 (from https://files.pythonhosted.org/packages/03/00/ae8ee7447dc675c5f9eb02afde95dcadb4442abbeb64f3656b19874e47de/flwr-0.4.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.3.0 depends on flwr 0.3.0 (from https://files.pythonhosted.org/packages/71/33/fefccbaaf53994ef24d1ad730c33f108efc04a07a40aaeddaeeca91d6786/flwr-0.3.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.2.0 depends on flwr 0.2.0 (from https://files.pythonhosted.org/packages/d1/32/eb1e02f44fbdef5a7d7f9d8dae2aecc2200f83fe589f2c8b817444f34df2/flwr-0.2.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.1.1 depends on flwr 0.1.1 (from https://files.pythonhosted.org/packages/71/4f/d6e4cf239371cebcf4392744c72861747e2a56df8b6d681e07e1614442df/flwr-0.1.1-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "    The user requested flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower)\n",
      "    flwr[simulation] 0.1.0 depends on flwr 0.1.0 (from https://files.pythonhosted.org/packages/96/eb/60872dfdf671ba8af4254eaab54ed56b2e5a2de72e37d5c41227afb5f614/flwr-0.1.0-py3-none-any.whl (from https://pypi.org/simple/flwr/) (requires-python:>=3.6.9,<4.0.0))\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: flwr 0.16.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.15.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.14.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.13.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.12.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.11.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.10.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.9.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.7.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.6.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.5.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.4.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.3.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.2.0 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.1.1 does not provide the extra 'simulation'\n",
      "WARNING: flwr 0.1.0 does not provide the extra 'simulation'\n",
      "ERROR: Cannot install flwr 1.5.0 (from C:\\Users\\Elnathan Tiokou\\flower), flwr[simulation]==0.1.0, flwr[simulation]==0.1.1, flwr[simulation]==0.10.0, flwr[simulation]==0.11.0, flwr[simulation]==0.12.0, flwr[simulation]==0.13.0, flwr[simulation]==0.14.0, flwr[simulation]==0.15.0, flwr[simulation]==0.16.0, flwr[simulation]==0.17.0, flwr[simulation]==0.18.0, flwr[simulation]==0.19.0, flwr[simulation]==0.2.0, flwr[simulation]==0.3.0, flwr[simulation]==0.4.0, flwr[simulation]==0.5.0, flwr[simulation]==0.6.0, flwr[simulation]==0.7.0, flwr[simulation]==0.9.0, flwr[simulation]==1.0.0, flwr[simulation]==1.1.0, flwr[simulation]==1.2.0, flwr[simulation]==1.3.0, flwr[simulation]==1.4.0 and flwr[simulation]==1.5.0 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "# To launch first \n",
    "%pip install flwr[simulation] torch torchvision matplotlib -e ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  flwr[simulation] torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib torch torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "field() got an unexpected keyword argument 'alias'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader, random_split\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m CIFAR10\n\u001b[1;32m---> 12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mflwr\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mfl\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39m#import tensorflow_privacy as tfp\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflwr\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m \u001b[39mimport\u001b[39;00m Metrics\n",
      "File \u001b[1;32m~\\Flower\\src\\py\\flwr\\__init__.py:20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Flower main package.\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflwr\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m package_version \u001b[39mas\u001b[39;00m _package_version\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m client, common, driver, server, simulation\n\u001b[0;32m     22\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     23\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mclient\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcommon\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msimulation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m ]\n\u001b[0;32m     30\u001b[0m __version__ \u001b[39m=\u001b[39m _package_version\n",
      "File \u001b[1;32m~\\Flower\\src\\py\\flwr\\simulation\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m is_ray_installed \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mfind_spec(\u001b[39m\"\u001b[39m\u001b[39mray\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mif\u001b[39;00m is_ray_installed:\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mflwr\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msimulation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapp\u001b[39;00m \u001b[39mimport\u001b[39;00m start_simulation\n\u001b[0;32m     24\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     RAY_IMPORT_ERROR: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mUnable to import module `ray`.\u001b[39m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[39mTo install the necessary dependencies, install `flwr` with the `simulation` extra:\u001b[39m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m    pip install -U flwr[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msimulation\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[39m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m~\\Flower\\src\\py\\flwr\\simulation\\app.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m ERROR, INFO\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Callable, Dict, List, Optional, Type, Union\n\u001b[1;32m---> 23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mray\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscheduling_strategies\u001b[39;00m \u001b[39mimport\u001b[39;00m NodeAffinitySchedulingStrategy\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflwr\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m ClientLike\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\ray\\__init__.py:136\u001b[0m\n\u001b[0;32m    128\u001b[0m _config \u001b[39m=\u001b[39m _Config()\n\u001b[0;32m    130\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstate\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa: E402,F401\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     nodes,\n\u001b[0;32m    132\u001b[0m     timeline,\n\u001b[0;32m    133\u001b[0m     cluster_resources,\n\u001b[0;32m    134\u001b[0m     available_resources,\n\u001b[0;32m    135\u001b[0m )\n\u001b[1;32m--> 136\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mworker\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa: E402,F401\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     LOCAL_MODE,\n\u001b[0;32m    138\u001b[0m     SCRIPT_MODE,\n\u001b[0;32m    139\u001b[0m     WORKER_MODE,\n\u001b[0;32m    140\u001b[0m     RESTORE_WORKER_MODE,\n\u001b[0;32m    141\u001b[0m     SPILL_WORKER_MODE,\n\u001b[0;32m    142\u001b[0m     cancel,\n\u001b[0;32m    143\u001b[0m     get,\n\u001b[0;32m    144\u001b[0m     get_actor,\n\u001b[0;32m    145\u001b[0m     get_gpu_ids,\n\u001b[0;32m    146\u001b[0m     init,\n\u001b[0;32m    147\u001b[0m     is_initialized,\n\u001b[0;32m    148\u001b[0m     put,\n\u001b[0;32m    149\u001b[0m     kill,\n\u001b[0;32m    150\u001b[0m     remote,\n\u001b[0;32m    151\u001b[0m     shutdown,\n\u001b[0;32m    152\u001b[0m     wait,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    155\u001b[0m \u001b[39m# We import ray.actor because some code is run in actor.py which initializes\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39m# some functions in the worker.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactor\u001b[39;00m  \u001b[39m# noqa: E402,F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\ray\\_private\\worker.py:59\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mstorage\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# Ray modules\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactor\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcloudpickle\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjob_config\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\ray\\actor.py:38\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplacement_group\u001b[39;00m \u001b[39mimport\u001b[39;00m _configure_placement_group_based_on_context\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscheduling_strategies\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m     PlacementGroupSchedulingStrategy,\n\u001b[0;32m     36\u001b[0m     SchedulingStrategyT,\n\u001b[0;32m     37\u001b[0m )\n\u001b[1;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtracing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtracing_helper\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     _inject_tracing_into_class,\n\u001b[0;32m     40\u001b[0m     _tracing_actor_creation,\n\u001b[0;32m     41\u001b[0m     _tracing_actor_method_invocation,\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[39m# Hook to call with (actor, resources, strategy) on each local actor creation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py:28\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mworker\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minspect_util\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     is_class_method,\n\u001b[0;32m     25\u001b[0m     is_function_or_method,\n\u001b[0;32m     26\u001b[0m     is_static_method,\n\u001b[0;32m     27\u001b[0m )\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime_context\u001b[39;00m \u001b[39mimport\u001b[39;00m get_runtime_context\n\u001b[0;32m     30\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_OpenTelemetryProxy\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\ray\\runtime_context.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mworker\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient_mode_hook\u001b[39;00m \u001b[39mimport\u001b[39;00m client_mode_hook\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime_env\u001b[39;00m \u001b[39mimport\u001b[39;00m RuntimeEnv\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mannotations\u001b[39;00m \u001b[39mimport\u001b[39;00m Deprecated, PublicAPI\n\u001b[0;32m      9\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\ray\\runtime_env\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime_env\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime_env\u001b[39;00m \u001b[39mimport\u001b[39;00m RuntimeEnv, RuntimeEnvConfig  \u001b[39m# noqa: E402,F401\u001b[39;00m\n\u001b[0;32m      3\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRuntimeEnvConfig\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRuntimeEnv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\ray\\runtime_env\\runtime_env.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime_env\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconda\u001b[39;00m \u001b[39mimport\u001b[39;00m get_uri \u001b[39mas\u001b[39;00m get_conda_uri\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime_env\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpip\u001b[39;00m \u001b[39mimport\u001b[39;00m get_uri \u001b[39mas\u001b[39;00m get_pip_uri\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime_env\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugin_schema_manager\u001b[39;00m \u001b[39mimport\u001b[39;00m RuntimeEnvPluginSchemaManager\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mruntime_env\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m OPTION_TO_VALIDATION_FN\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mthirdparty\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdacite\u001b[39;00m \u001b[39mimport\u001b[39;00m from_dict\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\ray\\_private\\runtime_env\\plugin_schema_manager.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjsonschema\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\jsonschema\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjsonschema\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_types\u001b[39;00m \u001b[39mimport\u001b[39;00m TypeChecker\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjsonschema\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m SchemaError, ValidationError\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjsonschema\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidators\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     Draft3Validator,\n\u001b[0;32m     18\u001b[0m     Draft4Validator,\n\u001b[0;32m     19\u001b[0m     Draft6Validator,\n\u001b[0;32m     20\u001b[0m     Draft7Validator,\n\u001b[0;32m     21\u001b[0m     Draft201909Validator,\n\u001b[0;32m     22\u001b[0m     Draft202012Validator,\n\u001b[0;32m     23\u001b[0m     validate,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(name):\n\u001b[0;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__version__\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\jsonschema\\validators.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattrs\u001b[39;00m \u001b[39mimport\u001b[39;00m define, field, fields\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjsonschema_specifications\u001b[39;00m \u001b[39mimport\u001b[39;00m REGISTRY \u001b[39mas\u001b[39;00m SPECIFICATIONS\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrpds\u001b[39;00m \u001b[39mimport\u001b[39;00m HashTrieMap\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mreferencing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\jsonschema_specifications\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mThe JSON Schema meta-schemas and vocabularies, exposed as a Registry.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mreferencing\u001b[39;00m \u001b[39mimport\u001b[39;00m Registry \u001b[39mas\u001b[39;00m _Registry\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mreferencing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjsonschema\u001b[39;00m \u001b[39mimport\u001b[39;00m SchemaRegistry \u001b[39mas\u001b[39;00m _SchemaRegistry\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjsonschema_specifications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_core\u001b[39;00m \u001b[39mimport\u001b[39;00m _schemas\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\referencing\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mCross-specification, implementation-agnostic JSON referencing.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mreferencing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_core\u001b[39;00m \u001b[39mimport\u001b[39;00m Anchor, Registry, Resource, Specification\n\u001b[0;32m      6\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mAnchor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRegistry\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mResource\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSpecification\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\referencing\\_core.py:29\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m     20\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m     21\u001b[0m         segments: Sequence[\u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m],\n\u001b[0;32m     22\u001b[0m         resolver: Resolver[D],\n\u001b[0;32m     23\u001b[0m         subresource: Resource[D],\n\u001b[0;32m     24\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Resolver[D]:\n\u001b[0;32m     25\u001b[0m         \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[39m@frozen\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSpecification\u001b[39;00m(Generic[D]):\n\u001b[0;32m     30\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m    A specification which defines referencing behavior.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m    The various methods of a `Specification` allow for varying referencing\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m    behavior across JSON Schema specification versions, etc.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[39m#: A short human-readable name for the specification, used for debugging.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elnathan Tiokou\\anaconda3\\envs\\flwr\\lib\\site-packages\\referencing\\_core.py:55\u001b[0m, in \u001b[0;36mSpecification\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m maybe_in_subresource: _MaybeInSubresource[D]\n\u001b[0;32m     51\u001b[0m \u001b[39m#: Retrieve the anchors contained in the given document.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m _anchors_in: Callable[\n\u001b[0;32m     53\u001b[0m     [Specification[D], D],\n\u001b[0;32m     54\u001b[0m     Iterable[AnchorType[D]],\n\u001b[1;32m---> 55\u001b[0m ] \u001b[39m=\u001b[39m field(alias\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39manchors_in\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     57\u001b[0m \u001b[39m#: An opaque specification where resources have no subresources\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m#: nor internal identifiers.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m OPAQUE: ClassVar[Specification[Any]]\n",
      "\u001b[1;31mTypeError\u001b[0m: field() got an unexpected keyword argument 'alias'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import flwr as fl\n",
    "    #import tensorflow_privacy as tfp\n",
    "from flwr.common import Metrics\n",
    "from flwr.server.history import History\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Downloading and preprocessing the data\n",
    "\n",
    "We will use a convolutional neural network (CNN) on the popular CIFAR-10 dataset (10 Classes) in a Federated Learning setting of 50 clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting our constants\n",
    "\n",
    "NUM_CLIENTS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into 10 partitions to simulate the individual dataset\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Training and Evaluation functions\n",
    "\n",
    "Let's define our model (including `set_parameters` and `get_parameters`), training and test functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flower client\n",
    "\n",
    "We create a subclass of `flwr.client.DPFedAvgNumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`. Here, we also pass the `cid` to the client and use it log additional details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient (fl.client.DPFedAvgNumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Strategy customization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP-FedAvg Modification\n",
    "Originally proposed by McMahan, H. Brendan, et al.,\"Learning differentially private recurrent language models\". DP-FedAvg, has been extended by [Andrew et al. 2021, Differentially Private Learning with Adaptive Clipping](https://arxiv.org/abs/1905.03871), is essentially FedAvg with the following modifications:\n",
    "\n",
    "To guarantee DP at a user-level, we need to apply the following modification in our Federated Averaging algorithm:\n",
    "\n",
    " - **Clipping:**, the clients' model updates must be clipped before transmission to the server, bounding the maximum influence of any one client. Moreover, knowing that the distribution of the update norm has been shown to vary from task-to-task and to evolve as training progresses. Therefore, we will use an adaptive approach of [Andrew et al. 2021, Differentially Private Learning with Adaptive Clipping](#dp-fedavg-modification) that continuously adjusts the clipping threshold to track a prespecified quantile of the update norm distribution.\n",
    " - **Noising:** Gaussian noise must be added by either the server or the clients. Adding noise could degrade the utility of the model, but we can control it using   the standard deviation of the Gaussian noise added to the sum, and the number of sampled clients at each round.\n",
    " >>>> *We provide users with the flexibility to set up the training such that each client independently adds a small amount of noise to the clipped update, with the result that simply aggregating the noisy updates is equivalent to the explicit addition of noise to the non-noisy aggregate at the server.*\n",
    "\n",
    "\n",
    " > *Remarks:* In order to do this, we need first to determine how much noise the model can tolerate with the chosed number of clients (relatively small) per round with fair loss to the model utility. We will eventually train the final model with an increased amount of noise with proportional increased number of clients. \n",
    "\n",
    "### Simplifying assumptions for the training process\n",
    "\n",
    "To ensure that the training process realises the $(\\epsilon, \\delta )$-guarantees at the user-level, we made the following assumptions:\n",
    "\n",
    "-**Fixed-size subsampling** :Fixed-size subsamples of the clients must be taken at each round, as opposed to variable-sized Poisson subsamples.\n",
    "\n",
    "-**Unweighted averaging** : The contributions from all the clients must weighted equally in the aggregate to eliminate the requirement for the server to know in advance the sum of the weights of all clients available for selection.\n",
    "\n",
    "-**No client failures** : The set of available clients must stay constant across all rounds of training. In other words, clients cannot drop out or fail.\n",
    "\n",
    "\n",
    " >*Note:* The dataset should be large enough to support the selected number of clients. It is also important to note that since we are using an adaptative clipping, and the noise multiplier being the ratio of the noise standard deviation to the clipping norm; therefore the magnitude of the noise will change from rounds to rounds. \n",
    " >>*The above assumptions are in line with the contraints imposed by [Andrew et al.](#dp-fedavg-modification)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Determine the noise sensitivity of the model\n",
    "\n",
    "For our setting we have 50 clients (each holding 45 training and 5 validation examples). The number of training examples on each client being very small, let's configure the clients to perform 3 local training epoch. We also adjust the fraction of clients selected for training during each round (we don't want all 50 clients participating in every round), so we adjust `fraction_fit` to `0.5`, which means that only 50% of available clients (25 clients) will be selected for training each round.\n",
    "\n",
    "\n",
    "> *NB:* All these specifications will be wrapped in a customized function called `dp_experiment` for a proper and easy computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric aggregation function\n",
    "def unweighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by a neutral number of example\n",
    "    num_examples = 1\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for _ , m in metrics]\n",
    "    examples = [num_examples for _ , _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "\n",
    "#Configure the clients to perform 3 local training epoch\n",
    "def fit_config(server_round: int):\n",
    "    config = {\n",
    "        \"server_round\": server_round,\n",
    "        \"local_epochs\": 3,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "def dp_experiment(NUM_CLIENTS, NUM_ROUNDS, noise_multiplier)-> History:\n",
    "    \n",
    "    strategy1 = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=0.5, # Train on 50 clients (each round)\n",
    "        fraction_evaluate=0.25,  # Evaluate on 25 clients (each round)\n",
    "        min_fit_clients=3,\n",
    "        min_evaluate_clients=3,\n",
    "        min_available_clients=NUM_CLIENTS,\n",
    "        evaluate_metrics_aggregation_fn= unweighted_average,\n",
    "        on_fit_config_fn=fit_config,\n",
    "        initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(Net())),\n",
    "    )\n",
    "\n",
    "    strategy = fl.server.strategy.DPFedAvgAdaptive(\n",
    "        strategy = strategy1 ,\n",
    "        num_sampled_clients =  strategy1.num_fit_clients(NUM_CLIENTS)[0], \n",
    "        init_clip_norm = 0.3 ,\n",
    "        noise_multiplier = noise_multiplier, # Must be carefully chose accordingly to the clip_count_stddev bellow\n",
    "        server_side_noising = False ,\n",
    "        clip_norm_target_quantile = 0.5 ,\n",
    "        clip_count_stddev = None,  # if not specified, it takes the default value 'self.num_sampled_clients` / 20.0\n",
    "    )\n",
    "\n",
    "    # Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 0}\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        client_resources = {\"num_gpus\": 1}\n",
    "\n",
    "    # Start simulation\n",
    "    return fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients= NUM_CLIENTS,\n",
    "        config=fl.server.ServerConfig(NUM_ROUNDS),  # Just three rounds\n",
    "        strategy=strategy,\n",
    "        client_resources=client_resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = []\n",
    "NUM_ROUNDS = 5\n",
    "\n",
    "for noise_multiplier in [0.0, 0.5, 0.75, 1.0]:\n",
    "  print(f'Starting training with noise multiplier: {noise_multiplier}')\n",
    "  hist = dp_experiment(NUM_CLIENTS, NUM_ROUNDS, noise_multiplier)\n",
    "  record.append({\"Noise multiplier\": noise_multiplier, \"History\": hist})\n",
    "# print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i['History'].metrics_distributed for i in record])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the *$(\\epsilon, \\delta )$-analysis for a scaled FL*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two metrics are used to express the DP guarantee of an ML algorithm:\n",
    "\n",
    "1.   Epsilon ($\\epsilon$) - This is the privacy budget. It measures the strength of the privacy guarantee by bounding how much the probability of a particular model output can vary by including (or excluding) a single training point. A smaller value for $\\epsilon$ implies a better privacy guarantee. However, the $\\epsilon$ value is only an upper bound and a large value could still mean good privacy in practice.\n",
    "\n",
    "2. Delta ($\\delta$) - Bounds the probability of the privacy guarantee not holding. A general rule is to set it to be less than the inverse of the size of the training dataset. we set it to **10^-4** as the CIFAR10 dataset has 50,000 training points.\n",
    "\n",
    "\n",
    "> We use `dp_accounting.calibrate_dp_mechanism` to search over the number of clients per round. The privacy accountant (`RdpAccountant`) we use to estimate privacy given a `dp_accounting.DpEvent` is based on [Wang et al. (2018)](https://arxiv.org/abs/1808.00087) and [Mironov et al. (2019)](https://arxiv.org/pdf/1908.10530.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade dp-accounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dp_accounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_clients = 50000\n",
    "noise_to_clients_ratio = 0.005\n",
    "target_delta = 1e-4\n",
    "target_eps = 2\n",
    "rounds = 100\n",
    "\n",
    "# Initialize arguments to dp_accounting.calibrate_dp_mechanism.\n",
    "\n",
    "# No-arg callable that returns a fresh accountant.\n",
    "make_fresh_accountant = dp_accounting.rdp.RdpAccountant\n",
    "\n",
    "# Create function that takes expected clients per round and returns a \n",
    "# dp_accounting.DpEvent representing the full training process.\n",
    "def make_event_from_param(clients_per_round):\n",
    "  q = clients_per_round / total_clients\n",
    "  noise_multiplier = clients_per_round * noise_to_clients_ratio\n",
    "  gaussian_event = dp_accounting.GaussianDpEvent(noise_multiplier)\n",
    "  sampled_event = dp_accounting.PoissonSampledDpEvent(q, gaussian_event)\n",
    "  composed_event = dp_accounting.SelfComposedDpEvent(sampled_event, rounds)\n",
    "  return composed_event\n",
    "\n",
    "# Create object representing the search range [1, 3383].\n",
    "bracket_interval = dp_accounting.ExplicitBracketInterval(1, total_clients)\n",
    "\n",
    "# Perform search for smallest clients_per_round achieving the target privacy.\n",
    "clients_per_round = dp_accounting.calibrate_dp_mechanism(\n",
    "    make_fresh_accountant, make_event_from_param, target_eps, target_delta,\n",
    "    bracket_interval, discrete=True\n",
    ")\n",
    "\n",
    "noise_multiplier = clients_per_round * noise_to_clients_ratio\n",
    "print(f'To get ({target_eps}, {target_delta})-DP, use {clients_per_round} '\n",
    "      f'clients with noise multiplier {noise_multiplier}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
